МЕТОД УВЕЛИЧЕНИЯ ПРОИЗВОДИТЕЛЬНОСТИ ИНТЕРНЕТ-ОРИЕНТИРОВАННЫХ КЛИЕНТ-СЕРВЕРНЫХ ПРИЛОЖЕНИЙ
На примере конкретной технической задачи рассмотрены алгоритмы обработки данных в интернет-ориентированных клиент-серверных приложениях. Проведено практическое исследование производительности рассмотренных алгоритмов. Предложен метод выбора оптимального алгоритма с целью увеличения производительности интернет-ориентированных клиент-серверных приложений.
Ключевые слова: клиент-серверные приложения, производительность, обработка данных.
Введение
Переход к многоуровневой архитектуре интернет-ориентированных клиент-серверных приложений поставил перед разработчиками проблему распределения функций обработки данных между клиентской и серверной частями приложения.
Обозначенная проблема остаётся актуальной на стыке любых уровней многоуровневой архитектуры: уровня данных и уровня бизнес-логики, уровня бизнес-логики и уровня представления и т.п. Неверные технологические решения приводят к значительному падению производительности таких приложений, делая невозможной их работу под расчётной нагрузкой, а также значительно осложняя их дальнейшую модификацию и развитие.
В статье предложен метод увеличения производительности интернет-ориентированных клиент-серверных приложений, основанный на технологии тестирования производительности и повышении технической эффективности взаимодействия уровней данных и бизнес-логики.
Формулировка задачи
Дальнейшие рассуждения будут проводиться на основе следующей задачи, являющейся показательной в контексте исследования.
На уровне данных, представленном базой данных под управлением СУБД MySQL, хранится таблица, содержащая некоторое неизвестное количество записей (напр., новостей). Уровень бизнес-логики представлен программой на веб-ориентированном языке программирования PHP. Необходимо сформировать и представить конечному пользователю календарь новостей, содержащий ссылки только на те годы и месяцы, новости за которые представлены в базе данных. Отметим, что подобная задача является типичной для широкого спектра интернет-ресурсов. Рассмотрим варианты решения задачи, связанные с ними проблемы и пути их решения.
Проблема проектирования базы данных и выбора алгоритма обработки данных
СУБД MySQL поддерживает взаимодействие с клиентскими приложениями посредством языка структурированных запросов SQL. Язык SQL предоставляет программисту возможность реализовать часть обработки данных путём выполнения специальных запросов.
Такое решение позволяет упростить уровень бизнес-логики приложения, однако не всегда оказывается наиболее выгодным по критериям производительности и затрат оперативной памяти. Оптимизация обработки данных по двум вышеперечисленным критериям является нетривиальной задачей, требующей для своего решения выбора определённого алгоритма обработки данных и специального проектирования структуры базы данных, учитывающей особенности работы выбранного алгоритма.
Проблема выбора алгоритма. Для решения поставленной задачи в общем случае существует три алгоритма.
Алгоритм 1, основанный на прямой выборке данных сводится к извлечению всей информации с уровня данных на уровень бизнес-логики с последующим анализом и обработкой.
Алгоритм 2, основанный на частичной выборке данных предполагает формирование диапазонов значений, соответствующих указанным в исходной формулировке задачи, с последующей проверкой наличия записей, попадающих в сформированные диапазоны.
Алгоритм 3 предполагает совершенно иной подход основанный на формировании готового набора данных средствами СУБД, что позволяет на уровне бизнес-логики выполнить только небольшие преобразование форматов представления данных с целью дальнейшей их передачи на уровень представления.
Проблема проектирования базы данных. В контексте проектирования базы данных нас будут интересовать вопросы использования индексов и выбора типа данных для хранения даты-времени публикации новости.
Ответ на первый вопрос оказывается очевидным в случае, если количество операций чтения данных значительно превышает количество операций вставки и модификации данных.
Рассматриваемая задача относится как раз к такому случаю, поэтому мы используем индекс на поле news_dt.
Ответ на второй вопрос не является столь же очевидным. Несмотря на то, что СУБД MySQL предоставляет широкий набор типов данных для хранения даты-времени, операции с unixtime (целым числом, представляющим собой время, выраженное в количестве секунд, прошедших с 1 января 1970 года), как правило, оказываются более производительными.
Выбор формата хранения даты-времени также влияет на выбор того или иного из рассмотренных выше алгоритмов. Так, алгоритмы 1 и 2 не зависят от формата данных в базе данных, т.к. выполняют обработку информации на уровне бизнес-логики. Алгоритм 3 ориентирован в первую очередь на специализированный формат представления данных datetime, и его адаптация к формату unixtime негативно сказывается на производительности, т.к. требует дополнительных операций по преобразованию форматов данных.
Экспериментальное исследование
Перед формулировкой предлагаемого метода увеличения производительности интернет-ориентированных клиент-серверных приложений предлагается рассмотреть результаты тестирования производительности, проведённого с применением каждого из рассмотренных выше алгоритмов и обоих вариантов хранения данных в базе данных.
Исследование проводилось на наборах данных, содержащих 100, 1000, 10000, 100000 и 1000000 записей со случайными значениями даты-времени в диапазоне от 1970 до 2010 года. Программные средства, реализующие каждый алгоритм на каждом из вариантов хранения информации, запускались в случайном порядке не менее 1000 раз каждое. Для исследования использовалась СУБД MySQL версии 5.1.44, язык программирования PHP версии 5.3.0 и веб-сервер Apache версии 2.2.14.
Аппаратное обеспечение в данном случае не является значимым, поскольку основной интерес представляет относительная производительность рассмотренных выше алгоритмов на каждом из вариантов хранения данных.
Альтернативное исследование, проведённое путём исполнения тестируемых программных средств в консольном режиме (без применения веб-сервера Apache), показало, что для данной задачи наличие или отсутствие дополнительного уровня программного обеспечения (веб-сервера) не является принципиальным, поскольку веб-сервер в данном случае обеспечивает только передачу данных между уровнем представления и уровнем бизнес-логики, что не является вычислительно сложной задачей и занимает сравнительно малое время в сравнении со временем выполнения основной части алгоритма, реализующей основную логику решения поставленной задачи.
В пользу предлагаемого в настоящей статье метода говорит тот факт, что эксперимент по оценке производительности алгоритмов (который приходится неоднократно повторять при разработке реальных приложений) выполнялся на протяжении двух недель, что не может считаться допустимым при коммерческой разработке программного обеспечения.
Как показывает экспериментальное исследование, время работы алгоритма 1 жёстко зависит от количества обрабатываемых данных, в то время как время работы алгоритмов 2 и 3 остаётся на приемлемом уровне, и их производительность снижается незначительно. Особый интерес представляет тот факт, что алгоритм 2, показывавший худшую производительность на малых объёмах данных (отставание от лидера в 330-370 раз), на больших объёмах данных показал отставание всего в 1,2-2,1 раза. Экстраполяция полученных результатов на случай с ещё большими объёмами данных позволяет рассматривать данный алгоритм в качестве одного из наилучших кандидатов для решения поставленной задачи.
Отметим также, что все рассмотренные алгоритмы показали снижение производительности при проверке на 1000000 записей в сравнении с проверкой на 100000 записей, что вызвано необходимостью выполнения дополнительных операций с оперативной и внешней памятью на уровне данных и уровне бизнес-логики.
Управление такими операциями контролируется операционной системой и не всегда может быть оптимизировано средствами языка программирования, на котором реализовано решение поставленной задачи. Этот факт также является аргументом в пользу использования алгоритма 2, предъявляющего значительно меньшие требования к объёму используемой памяти.
В силу того факта, что производительность предложенных алгоритмов зависит не только от объёма обрабатываемых данных, ниже предложен метод выбора алгоритма, наиболее подходящего для решения тех или иных технических задач.
Формулировка предлагаемого метода
Предлагаемый в настоящей статье метод увеличения производительности интернет-ориентированных клиент-серверных приложений построен на анализе факторов, влияющих на производительность алгоритмов обработки данных.
К таким факторам относятся: вычислительная сложность обработки информации на уровне данных, вычислительная сложность [2] обработки информации на уровне бизнес-логики, объём обрабатываемых данных, объём данных, передаваемых между уровнями приложения, вычислительная сложность дополнительной обработки данных для их передачи на уровень представления, вычислительная сложность преобразования формата данных для их последующей обработки на уровне данных, плотность распределения данных по анализируемым диапазонам.
Заключение
Применение предложенного метода позволяет при определении оптимального алгоритма избежать необходимости выполнять длительное тестирование производительности, которое, в свою очередь, требует реализации всех конкурирующих алгоритмов. Таким образом, применение предложенного метода позволяет не только увеличить производительность интернет-ориентированных клиент-серверных приложений, но и сократить время и трудоёмкость их разработки.
Учёт количества обрабатываемой информации (2) и результаты практических исследований, представленные в таблице 3, позволяют прогнозировать изменение производительности программного средства, решающего сформулированную во введении к данной статье задачи. Такой прогноз позволяет ещё на стадии проектирования программного средства снизить риск недопустимого падения производительности, приводящего к необходимости внесения модификаций в программное средство на стадии его эксплуатации.

